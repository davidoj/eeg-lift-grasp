{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created on Mon Jun 29 14:00:37 2015\n",
      "\n",
      "@author: alexandrebarachant\n",
      "\n",
      "Beat the benchmark with CSP and Logisitic regression.\n",
      "\n",
      "General Idea :\n",
      "\n",
      "The goal of this challenge is to detect events related to hand movements. Hand \n",
      "movements are caracterized by change in signal power in the mu (~10Hz) and beta\n",
      "(~20Hz) frequency band over the sensorimotor cortex. CSP spatial filters are\n",
      "trained to enhance signal comming from this brain area, instantaneous power is\n",
      "extracted and smoothed, and then feeded into a logisitic regression.\n",
      "\n",
      "Preprocessing :\n",
      "\n",
      "Signal are bandpass-filtered between 7 and 30 Hz to catch most of the signal of\n",
      "interest. 4 CSP spatial filters are then applied to the signal, resutlting to\n",
      "4 new time series.  In order to train CSP spatial filters, EEG are epoched \n",
      "using a window of 2 second before and after the event 'HandStart'. CSP training\n",
      "needs two classes. the epochs after Replace event are assumed to contain \n",
      "patterns corresponding to hand movement, and epochs before are assumed to \n",
      "contain resting state.\n",
      "\n",
      "Feature extraction :\n",
      "\n",
      "Preprocessing is applied, spatialy filtered signal are the rectified and \n",
      "convolved with a 0.5 second rectangular window for smoothing. Then a logarithm\n",
      "is applied. the resutl is a vector of dimention 4 for each time sample.\n",
      "\n",
      "Classification :\n",
      "\n",
      "For each of the 6 event type, a logistic regression is trained. For training \n",
      "only, features are downsampled in oder to speed up the process. Prediction are\n",
      "the probailities of the logistic regression.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun 29 14:00:37 2015\n",
    "\n",
    "@author: alexandrebarachant\n",
    "\n",
    "Beat the benchmark with CSP and Logisitic regression.\n",
    "\n",
    "General Idea :\n",
    "\n",
    "The goal of this challenge is to detect events related to hand movements. Hand \n",
    "movements are caracterized by change in signal power in the mu (~10Hz) and beta\n",
    "(~20Hz) frequency band over the sensorimotor cortex. CSP spatial filters are\n",
    "trained to enhance signal comming from this brain area, instantaneous power is\n",
    "extracted and smoothed, and then feeded into a logisitic regression.\n",
    "\n",
    "Preprocessing :\n",
    "\n",
    "Signal are bandpass-filtered between 7 and 30 Hz to catch most of the signal of\n",
    "interest. 4 CSP spatial filters are then applied to the signal, resutlting to\n",
    "4 new time series.  In order to train CSP spatial filters, EEG are epoched \n",
    "using a window of 2 second before and after the event 'HandStart'. CSP training\n",
    "needs two classes. the epochs after Replace event are assumed to contain \n",
    "patterns corresponding to hand movement, and epochs before are assumed to \n",
    "contain resting state.\n",
    "\n",
    "Feature extraction :\n",
    "\n",
    "Preprocessing is applied, spatialy filtered signal are the rectified and \n",
    "convolved with a 0.5 second rectangular window for smoothing. Then a logarithm\n",
    "is applied. the resutl is a vector of dimention 4 for each time sample.\n",
    "\n",
    "Classification :\n",
    "\n",
    "For each of the 6 event type, a logistic regression is trained. For training \n",
    "only, features are downsampled in oder to speed up the process. Prediction are\n",
    "the probailities of the logistic regression.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne.io import RawArray\n",
    "from mne.channels import read_montage\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne import create_info, find_events, Epochs, concatenate_raws, pick_types\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from glob import glob\n",
    "\n",
    "from scipy.signal import butter, lfilter, convolve, boxcar\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def creat_mne_raw_object(fname,read_events=True):\n",
    "    \"\"\"Create a mne raw instance from csv file\"\"\"\n",
    "    # Read EEG file\n",
    "    data = pd.read_csv(fname)\n",
    "    \n",
    "    # get chanel names\n",
    "    ch_names = list(data.columns[1:])\n",
    "    \n",
    "    # read EEG standard montage from mne\n",
    "    montage = read_montage('standard_1005',ch_names)\n",
    "\n",
    "    ch_type = ['eeg']*len(ch_names)\n",
    "    data = np.array(data[ch_names]).T\n",
    "\n",
    "    if read_events:\n",
    "        # events file\n",
    "        ev_fname = fname.replace('_data','_events')\n",
    "        # read event file\n",
    "        events = pd.read_csv(ev_fname)\n",
    "        events_names = events.columns[1:]\n",
    "        events_data = np.array(events[events_names]).T\n",
    "        \n",
    "        # define channel type, the first is EEG, the last 6 are stimulations\n",
    "        ch_type.extend(['stim']*6)\n",
    "        ch_names.extend(events_names)\n",
    "        # concatenate event file and data\n",
    "        data = np.concatenate((data,events_data))\n",
    "        \n",
    "    # create and populate MNE info structure\n",
    "    info = create_info(ch_names,sfreq=500.0, ch_types=ch_type, montage=montage)\n",
    "    info['filename'] = fname\n",
    "    \n",
    "    # create raw object \n",
    "    raw = RawArray(data,info,verbose=False)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "subjects = range(1)\n",
    "ids_tot = []\n",
    "pred_tot = []\n",
    "\n",
    "# design a butterworth bandpass filter \n",
    "freqs = [7, 30]\n",
    "b,a = butter(5,np.array(freqs)/250.0,btype='bandpass')\n",
    "\n",
    "# CSP parameters\n",
    "# Number of spatial filter to use\n",
    "nfilters = 4\n",
    "\n",
    "# convolution\n",
    "# window for smoothing features\n",
    "nwin = 250\n",
    "\n",
    "# training subsample\n",
    "subsample = 10\n",
    "\n",
    "# submission file\n",
    "submission_file = 'beat_the_benchmark.csv'\n",
    "cols = ['HandStart','FirstDigitTouch',\n",
    "        'BothStartLoadPhase','LiftOff',\n",
    "        'Replace','BothReleased']\n",
    "\n",
    "for subject in subjects:\n",
    "    epochs_tot = []\n",
    "    y = []\n",
    "\n",
    "    ################ READ DATA ################################################\n",
    "    fnames =  glob('../train/subj%d_series1_data.csv' % (subject))\n",
    "    fname = '../train/subj1_series1_data.csv'\n",
    "    # read and concatenate all the files\n",
    "    #raw = concatenate_raws([creat_mne_raw_object(fname) for fname in fnames])\n",
    "    raw = creat_mne_raw_object(fname)\n",
    "    # pick eeg signal\n",
    "    picks = pick_types(raw.info,eeg=True)\n",
    "    \n",
    "    # Filter data for alpha frequency and beta band\n",
    "    # Note that MNE implement a zero phase (filtfilt) filtering not compatible\n",
    "    # with the rule of future data.\n",
    "    # Here we use left filter compatible with this constraint. \n",
    "    # The function parallelized for speeding up the script\n",
    "    #raw._data[picks] = np.array(Parallel(n_jobs=-1)(delayed(lfilter)(b,a,raw._data[i]) for i in picks))\n",
    "    \n",
    "    ################ CSP Filters training #####################################\n",
    "    # get event posision corresponding to HandStart\n",
    "    events = find_events(raw,stim_channel='HandStart', verbose=False)\n",
    "\n",
    "    # epochs signal for 2 second after the event\n",
    "    epochs = Epochs(raw, events, {'during' : 1}, 0, 2, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose=False)\n",
    "\n",
    "    epochs_tot.append(epochs)\n",
    "    y.extend([1]*len(epochs))\n",
    "    \n",
    "    # epochs signal for 2 second before the event, this correspond to the \n",
    "    # rest period.\n",
    "    epochs_rest = Epochs(raw, events, {'before' : 1}, -2, 0, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose=False)\n",
    "    \n",
    "    # Workaround to be able to concatenate epochs with MNE\n",
    "    epochs_rest.times = epochs.times\n",
    "    \n",
    "    y.extend([-1]*len(epochs_rest))\n",
    "    epochs_tot.append(epochs_rest)\n",
    "        \n",
    "    # Concatenate all epochs\n",
    "    epochs = concatenate_epochs(epochs_tot)\n",
    "    \n",
    "    # get data \n",
    "    X = epochs.get_data()\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # train CSP\n",
    "    csp = CSP(n_components=nfilters, reg='lws')\n",
    "    csp.fit(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csp.filters_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 234.,  470.,  248.,  203.,  264.,  516.,  499.,  482.,   50.,\n",
       "        177.,  582., -229.,  213.,  169.,  541.,  707.,  196.,   20.,\n",
       "        291.,  456.,  266.,  350.,  556.,  385.,  441.,  127.,  564.,\n",
       "        314.,  530.,  275.,  184.,  695.,    0.,    0.,    0.,    0.,\n",
       "          0.,    0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw._data[:,68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 103.,   87.,   79., ...,   65.,   93.,   95.],\n",
       "        [ 343.,  337.,  272., ...,  269.,  332.,  380.],\n",
       "        [ 450.,  424.,  434., ...,  381.,  344.,  355.],\n",
       "        ..., \n",
       "        [ -74.,  -45.,  -60., ..., -106., -205., -205.],\n",
       "        [-112.,  -73.,  -92., ..., -161., -253., -252.],\n",
       "        [  45.,   93.,   17., ...,  122.,   45.,    7.]],\n",
       "\n",
       "       [[ 234.,  194.,  214., ...,  493.,  474.,  435.],\n",
       "        [ 470.,  540.,  547., ...,  506.,  342.,  206.],\n",
       "        [ 248.,  233.,  361., ...,  696.,  758.,  762.],\n",
       "        ..., \n",
       "        [ 275.,  261.,  282., ...,   -4., -104.,  -46.],\n",
       "        [ 184.,  151.,  171., ...,  -60., -110.,  -71.],\n",
       "        [ 695.,  650.,  669., ...,  436.,  400.,  449.]],\n",
       "\n",
       "       [[ -30.,   15.,   49., ...,  465.,  516.,  554.],\n",
       "        [ 610.,  628.,  599., ...,  617.,  520.,  443.],\n",
       "        [ 604.,  537.,  513., ...,  525.,  535.,  522.],\n",
       "        ..., \n",
       "        [ 404.,  420.,  394., ...,  209.,  173.,  156.],\n",
       "        [ 414.,  430.,  404., ...,  335.,  273.,  209.],\n",
       "        [ 823.,  835.,  816., ...,  509.,  446.,  422.]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[33:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
