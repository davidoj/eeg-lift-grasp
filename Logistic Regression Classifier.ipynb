{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression classifier\n",
    "\n",
    "Classifying data with logit regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import LeaveOneLabelOut\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from mne.io import RawArray\n",
    "from mne.channels import read_montage\n",
    "from mne.epochs import concatenate_epochs\n",
    "from mne import create_info, find_events, Epochs, concatenate_raws, pick_types\n",
    "from mne.decoding import CSP\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from preprocessing import *\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Data preparation\n",
    "\n",
    "def prepare_data_train(fname):\n",
    "    \"\"\" read and prepare training data \"\"\"\n",
    "    data = pd.read_csv(fname)\n",
    "    events_fname = fname.replace('_data','_events')\n",
    "    labels= pd.read_csv(events_fname)\n",
    "    clean=data.drop(['id' ], axis=1)\n",
    "    labels=labels.drop(['id' ], axis=1)\n",
    "    return  clean,labels\n",
    "\n",
    "def prepare_data_test(fname):\n",
    "    \"\"\" read and prepare test data \"\"\"\n",
    "    data = pd.read_csv(fname)\n",
    "    return data\n",
    "\n",
    "-\n",
    "\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
    "def fit(X,y):\n",
    "    # Do here you training\n",
    "    clf = LDA()\n",
    "    clf.fit(X,y)\n",
    "    return clf\n",
    "\n",
    "def predict(clf,X):\n",
    "    # do here your prediction\n",
    "    preds = clf.predict_proba(X)\n",
    "    return np.atleast_2d(preds[:,clf.classes_==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Parameters\n",
    "cols = ['HandStart','FirstDigitTouch',\n",
    "        'BothStartLoadPhase','LiftOff',\n",
    "        'Replace','BothReleased']\n",
    "scaler= StandardScaler()\n",
    "nfilters = 4\n",
    "csp = CSP(n_components=nfilters, reg='lws')\n",
    "bands = [[5,20]]\n",
    "subsample = 50\n",
    "cut = 3\n",
    "cpast = [20,7]\n",
    "subjects = range(1,13)\n",
    "series = range(1,9)\n",
    "\n",
    "### Don't think I need this\n",
    "\n",
    "# events = ['HandStart','FirstDigitTouch',\n",
    "#            'BothStartLoadPhase','LiftOff',\n",
    "#            'Replace','BothReleased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject=1ser=1\n",
      "subject=1ser=2\n",
      "subject=1ser=3\n",
      "subject=1ser=4\n",
      "(605608, 6) (605608, 352)\n",
      "(119296, 1)\n",
      "(453150, 6) (453150, 352)\n",
      "(271754, 1)\n",
      "(507490, 6) (507490, 352)\n",
      "(217414, 1)\n",
      "(608864, 6) (608864, 352)\n",
      "(116040, 1)\n",
      "[0.90039367430254835, 0.95031895304267699, 0.95155662028057775, 0.91123394255309353, 0.9234649529345621, 0.91523167385468684]\n",
      "subject=2ser=1\n",
      "subject=2ser=3\n",
      "subject=2ser=4\n",
      "(430659, 6) (430659, 352)\n",
      "(291674, 1)\n",
      "(569788, 6) (569788, 352)\n",
      "(152545, 1)\n",
      "(444419, 6) (444419, 352)\n",
      "(277914, 1)\n",
      "[0.81372133758455112, 0.78309795283040917, 0.82201424815376389, 0.78250908828859056, 0.81637466074493847, 0.77944242150231613]\n",
      "subject=3ser=1\n",
      "subject=3ser=2\n",
      "subject=3ser=3\n",
      "subject=3ser=4\n",
      "(618433, 6) (618433, 352)\n",
      "(122062, 1)\n",
      "(547835, 6) (547835, 352)\n",
      "(192660, 1)\n",
      "(511338, 6) (511338, 352)\n",
      "(229157, 1)\n",
      "(544279, 6) (544279, 352)\n",
      "(196216, 1)\n",
      "[0.82744841993713736, 0.84477614472893947, 0.8643497151068722, 0.83836983574682455, 0.79497703694176125, 0.81554585663216417]\n",
      "subject=4ser=1\n",
      "subject=4ser=2\n",
      "subject=4ser=3\n",
      "subject=4ser=4\n",
      "(545611, 6) (545611, 352)\n",
      "(246412, 1)\n",
      "(583499, 6) (583499, 352)\n",
      "(208524, 1)\n",
      "(660728, 6) (660728, 352)\n",
      "(131295, 1)\n",
      "(586631, 6) (586631, 352)\n",
      "(205392, 1)\n",
      "[0.8747549062336627, 0.91581811226342658, 0.91791115845738336, 0.90539196875187733, 0.85142428148839411, 0.8691252549709938]\n"
     ]
    }
   ],
   "source": [
    "pred_tot = []\n",
    "y_tot = []\n",
    "auc_tot = []\n",
    "for subject in subjects:\n",
    "    y_raw= []\n",
    "    raw = []\n",
    "    sequence = []\n",
    "\n",
    "    ################ READ DATA ################################################\n",
    "    \n",
    "    for ser in series:\n",
    "        if ser==2 and subject ==2:\n",
    "            continue\n",
    "        fname =  '../train/subj%d_series%d_data.csv' % (subject,ser)\n",
    "        print(\"subject=\" + str(subject) + \"ser=\" + str(ser))\n",
    "        data,labels=prepare_data_train(fname)\n",
    "        raw.append(data) \n",
    "        y_raw.append(labels)\n",
    "        sequence.extend([ser]*len(data))\n",
    "\n",
    "    X = pd.concat(raw)\n",
    "    y = pd.concat(y_raw)\n",
    "    #transform in numpy array\n",
    "    #transform train data in numpy array\n",
    "    X = np.asarray(X.astype(float))\n",
    "    y = np.asarray(y.astype(float))\n",
    "    sequence = np.asarray(sequence)\n",
    "\n",
    "\n",
    "    ################ Train classifiers ########################################\n",
    "    cv = LeaveOneLabelOut(sequence)\n",
    "    pred = np.empty((X.shape[0],6))\n",
    "    \n",
    "    for train, test in cv:\n",
    "        test_s = test[cpast[0]*cpast[1]:]\n",
    "        train_s = train[cpast[0]*cpast[1]:]\n",
    "        X_train = X[train]\n",
    "        X_test = X[test]\n",
    "        y_train = y[train_s]\n",
    "        #apply preprocessing\n",
    "        X_train = data_preprocess_train(X_train,events=labels,lpass=cut,sca=1,cpast=cpast,fbands=bands)\n",
    "        X_test=data_preprocess_test(X_test,sca=1,lpass=cut,cpast=cpast,fbands=bands)\n",
    "        print(y_train.shape,X_train.shape)\n",
    "        clfs = Parallel(n_jobs=6)(delayed(fit)(X_train[::subsample,:],y_train[::subsample,i]) for i in range(6))\n",
    "        preds = Parallel(n_jobs=6)(delayed(predict)(clfs[i],X_test) for i in range(6))\n",
    "        print(preds[0].shape)\n",
    "        pred[test_s,:] = np.concatenate(preds,axis=1)\n",
    "        \n",
    "    pred_tot.append(pred)\n",
    "    y_tot.append(y)\n",
    "    # get AUC\n",
    "    auc = [roc_auc_score(y[:,i],pred[:,i]) for i in range(6)]     \n",
    "    auc_tot.append(auc)\n",
    "    print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8553658740812603"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(auc_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86121884238883961"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(auc_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.66823505,  1.77759264, -0.55579713,  0.42364353])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs[0].coef_[0][[18,19,20,29]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = []\n",
    "for i, subject in enumerate(subjects):\n",
    "    X_test = prepare_data_test('../test/subj%d_series10_data.csv' %(subject))\n",
    "    idx.append(np.array(X_test['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pandas/core/internals.py:1191: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  values = values[:, slicer]\n",
      "/usr/lib/python3/dist-packages/pandas/core/internals.py:1196: DeprecationWarning: numpy boolean negative (the unary `-` operator) is deprecated, use the bitwise_xor (the `^` operator) or the logical_xor function instead.\n",
      "  imask = (-mask).ravel()\n",
      "/usr/lib/python3/dist-packages/pandas/core/index.py:624: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  result = arr_idx[key]\n"
     ]
    }
   ],
   "source": [
    "pred_tot = []\n",
    "y_tot = []\n",
    "auc_tot = []\n",
    "ids_tot = []\n",
    "idx = []\n",
    "for i, subject in enumerate(subjects):\n",
    "    y_raw= []\n",
    "    raw = []\n",
    "    raw_test = []\n",
    "    ################ READ DATA ################################################\n",
    "    \n",
    "    for ser in series:\n",
    "        if ser==2 and subject ==2:\n",
    "            continue\n",
    "        fname =  '../train/subj%d_series%d_data.csv' % (subject,ser)\n",
    "        data,labels=prepare_data_train(fname)\n",
    "        raw.append(data) \n",
    "        y_raw.append(labels)   \n",
    "\n",
    "    for k in range(9,11):\n",
    "        X_test = prepare_data_test('../test/subj%d_series%d_data.csv' %(subject,k))\n",
    "        idx.append(np.array(X_test['id']))   \n",
    "        X_test = X_test.drop(['id'],axis=1)\n",
    "        raw_test.append(X_test)\n",
    "    X_test = pd.concat(raw_test)\n",
    "    X_train = pd.concat(raw)\n",
    "    y_train = pd.concat(y_raw)\n",
    "    #transform in numpy array\n",
    "    #transform train data in numpy array\n",
    "    X_train = np.asarray(X_train.astype(float))\n",
    "    y_train = np.asarray(y_train.astype(float))\n",
    "    #sequence = np.asarray(sequence)\n",
    "\n",
    "\n",
    "    ################ Train classifiers ########################################\n",
    "    #cv = LeaveOneLabelOut(sequence)\n",
    "    pred = np.empty((X_test.shape[0],6))\n",
    "    \n",
    "    #apply preprocessing\n",
    "    X_train = data_preprocess_train(X_train,events=labels,lpass=cut,sca=1,cpast=cpast,fbands=bands)\n",
    "    X_test=data_preprocess_test(X_test,sca=1,lpass=cut,cpast=cpast,fbands=bands)\n",
    "    clfs = Parallel(n_jobs=3)(delayed(fit)(X_train[::subsample,:],y_train[cpast[0]*cpast[1]:][::subsample,i]) for i in range(6))\n",
    "    preds = Parallel(n_jobs=3)(delayed(predict)(clfs[i],X_test) for i in range(6))\n",
    "    #print(len(test),len(preds[0]))\n",
    "    pred[cpast[0]*cpast[1]:,:] = np.concatenate(preds,axis=1)\n",
    "        \n",
    "    pred_tot.append(pred)\n",
    "\n",
    "ids_tot=np.concatenate(idx)\n",
    "    \n",
    "submission_file = 'grasp_sub_fifth.csv'\n",
    "submission = pd.DataFrame(index=ids_tot,\n",
    "                          columns=cols,\n",
    "                          data=np.concatenate(pred_tot))\n",
    "                   \n",
    "submission.to_csv(submission_file,index_label='id',float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(index=ids_tot,\n",
    "                          columns=cols,\n",
    "                          data=np.concatenate(pred_tot))\n",
    "                   \n",
    "submission.to_csv(submission_file,index_label='id',float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn, fn2 = \"../train/subj1_series1_data.csv\", \"../train/subj1_series2_data.csv\"\n",
    "data, labels = prepare_data_train(fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.74308979879279602"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn, fn2 = \"../train/subj1_series1_data.csv\", \"../train/subj1_series2_data.csv\"\n",
    "data, labels = prepare_data_train(fn)\n",
    "\n",
    "y_train = labels[\"FirstDigitTouch\"]\n",
    "X_train = data_preprocess_train(data,sca=1)\n",
    "lr1 = LogisticRegression()\n",
    "lr1.fit(X_train[::subsample],y_train[::subsample]) \n",
    "\n",
    "eval_lr(lr1,sca=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/utils/validation.py:498: UserWarning: StandardScaler assumes floating point values as input, got int64\n",
      "  \"got %s\" % (estimator, X.dtype))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.83923819765432472"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2 = labels[\"FirstDigitTouch\"][100:]\n",
    "X_train2 = data_preprocess_train(data,cpast=[20,5],sca=1)\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train2[::subsample],y_train2[::subsample]) \n",
    "\n",
    "eval_lr(lr2,cpast=[20,5],sca=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75988739853284293"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band=[0.5,35]\n",
    "cut = 30\n",
    "\n",
    "y_train3 = labels[\"FirstDigitTouch\"]\n",
    "X_train3 = data_preprocess_train(data,lpass=cut,sca=1)\n",
    "lr3 = LogisticRegression()\n",
    "lr3.fit(X_train3[::subsample],y_train3[::subsample]) \n",
    "\n",
    "eval_lr(lr3,lpass=cut,sca=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81979610555588567"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut2 = 35\n",
    "\n",
    "y_train4 = labels[\"FirstDigitTouch\"][100:]\n",
    "X_train4 = data_preprocess_train(data,lpass=cut2,cpast=[20,5])\n",
    "lr4 = LogisticRegression()\n",
    "lr4.fit(X_train4[::subsample],y_train4[::subsample]) \n",
    "\n",
    "eval_lr(lr4,lpass=cut2,cpast=[20,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78239142541246032"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut2 = 35\n",
    "\n",
    "y_train5 = labels[\"FirstDigitTouch\"]\n",
    "X_train5 = data_preprocess_train(data,labels,lpass=cut2,csp_filt=1)\n",
    "lr5 = LogisticRegression()\n",
    "lr5.fit(X_train5[::subsample],y_train5[::subsample]) \n",
    "\n",
    "eval_lr(lr5,lpass=cut2,csp_filt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84497900944935445"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut2 = 35\n",
    "cpast = [19,10]\n",
    "\n",
    "y_train6 = labels[\"FirstDigitTouch\"][cpast[0]*cpast[1]:]\n",
    "X_train6 = data_preprocess_train(data,labels,lpass=cut2,cpast=cpast,csp_filt=1)\n",
    "lr6 = LogisticRegression()\n",
    "lr6.fit(X_train6[::subsample],y_train6[::subsample]) \n",
    "\n",
    "eval_lr(lr6,lpass=cut2,cpast=cpast,csp_filt=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_lr(lr5,bpass=1,cpast=1,pca=pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_lr(lr,cpast=[],lpass=None,bpass=None,pca=None,sca=None,csp_filt=None):\n",
    "    fns = glob(\"../train/subj1_series[2-9]_data.csv\")\n",
    "    scores = np.zeros(len(fns))\n",
    "    for i, fn in enumerate(fns):\n",
    "        data, labels = prepare_data_train(fn)\n",
    "        y_test = labels['FirstDigitTouch']\n",
    "        if len(cpast)>0:\n",
    "            y_test = y_test[cpast[0]*cpast[1]:]\n",
    "        X_test = data_preprocess_test(data,sca=sca,cpast=cpast,bpass=bpass,pca=pca,lpass=lpass,csp_filt=csp_filt)\n",
    "        pred = lr.predict_proba(X_test)[:,1]\n",
    "        \n",
    "        scores[i] = roc_auc_score(y_test,pred)\n",
    "        \n",
    "    return np.average(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Preprocessing functions, should be imported from preprocessing but here just in case\n",
    "\n",
    "\n",
    "def concat_past(X,interval=20,num_past=5):\n",
    "    frames = []\n",
    "    for i in range(num_past):\n",
    "        X_trunc  = X[i*interval:-(num_past-i)*interval]\n",
    "        frames.append(X_trunc)\n",
    "    X_out = np.concatenate(frames,axis=1)\n",
    "    return X_out\n",
    "\n",
    "\n",
    "def pd_concat_past(X,interval=20,num_past=5):\n",
    "    frames = []\n",
    "    for i in range(num_past):\n",
    "        X_trunc  = X[i*interval:-(num_past-i)*interval]\n",
    "        X_trunc = X_trunc.rename(index=lambda x: x-i*interval)\n",
    "        frames.append(X_trunc)\n",
    "    X_out = pd.concat(frames,axis=1)\n",
    "    return X_out\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data,axis=0)\n",
    "    return y\n",
    "\n",
    "def butter_lowpass(highcut,fs,order=5):\n",
    "    nyq = 0.5*fs\n",
    "    high = highcut/nyq\n",
    "    b,a = butter(order,high,btype=\"low\")\n",
    "    return b,a\n",
    "\n",
    "def butter_lowpass_filter(data,highcut,fs,order=5):\n",
    "    b, a = butter_lowpass(highcut,fs,order=order)\n",
    "    y = lfilter(b,a,data,axis=0)\n",
    "    return y\n",
    "\n",
    "\n",
    "def creat_mne_raw_object(data, events=[]):\n",
    "    \"\"\"Create a mne raw instance from csv file\"\"\"\n",
    "\n",
    "    ch_names = list(data.columns)\n",
    "    \n",
    "    # read EEG standard montage from mne\n",
    "    montage = read_montage('standard_1005',ch_names)\n",
    "\n",
    "    ch_type = ['eeg']*len(ch_names)\n",
    "    data = np.array(data[ch_names]).T\n",
    "\n",
    "    if len(events)>0:\n",
    "        events_names =list(events.columns)\n",
    "        events_data = np.array(events[events_names]).T     \n",
    "        # define channel type, the first is EEG, the last 6 are stimulations\n",
    "        ch_type.extend(['stim']*6)\n",
    "        ch_names.extend(events_names)\n",
    "        # concatenate event file and data\n",
    "        data = np.concatenate((data,events_data))\n",
    "        \n",
    "    # create and populate MNE info structure\n",
    "    info = create_info(ch_names,sfreq=500.0, ch_types=ch_type, montage=montage)\n",
    "    #info['filename'] = fname\n",
    "    \n",
    "    # create raw object \n",
    "    raw = RawArray(data,info,verbose=False)\n",
    "    \n",
    "    return raw\n",
    "\n",
    "def fit_CSP(data,events=[]):\n",
    "    epochs_tot = []\n",
    "    y = []\n",
    "    # read and concatenate all the files\n",
    "    #raw = concatenate_raws([creat_mne_raw_object(fname) for fname in fnames])\n",
    "    raw = creat_mne_raw_object(data,events=events)\n",
    "    # pick eeg signal\n",
    "    picks = pick_types(raw.info,eeg=True)\n",
    "\n",
    "    events = find_events(raw,stim_channel='HandStart', verbose=False)\n",
    "\n",
    "    epochs = Epochs(raw, events, {'during' : 1}, 0, 2, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose=False)\n",
    "\n",
    "    epochs_tot.append(epochs)\n",
    "    y.extend([1]*len(epochs))\n",
    "    \n",
    "    epochs_rest = Epochs(raw, events, {'before' : 1}, -2, 0, proj=False,\n",
    "                    picks=picks, baseline=None, preload=True,\n",
    "                    add_eeg_ref=False, verbose=False)\n",
    "    \n",
    "    epochs_rest.times = epochs.times\n",
    "    \n",
    "    y.extend([-1]*len(epochs_rest))\n",
    "    epochs_tot.append(epochs_rest)\n",
    "        \n",
    "    epochs = concatenate_epochs(epochs_tot)\n",
    "\n",
    "    X = epochs.get_data()\n",
    "    y = np.array(y)\n",
    "    \n",
    "\n",
    "    csp.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
